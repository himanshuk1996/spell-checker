{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords=stopwords.words('english')\n",
    "\n",
    "import string\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('ticketdata.xlsx')\n",
    "data['corpus'] = data['reason'] +\" \"+ data['initial_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(sentence, stopwords):\n",
    "\tsentencewords = sentence.split()\n",
    "\tresultwords  = [word for word in sentencewords if word.lower() not in stopwords]\n",
    "\tresult = ' '.join(resultwords)\n",
    "\treturn result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_NO_SPACE = re.compile(\"[^A-Za-z\\s]\")\n",
    "stemmer = nltk.SnowballStemmer('english')\n",
    "lemmatizer=nltk.WordNetLemmatizer()\n",
    "def preprocess_reviews(data):\n",
    "    data = [REPLACE_NO_SPACE.sub(\"\", str(line).lower()) for line in data]\n",
    "    data = [remove_stopwords(w,stopwords) for w in data]\n",
    "    #data = [lemmatizer.lemmatize(w) for w in data]\n",
    "    #data = [stemmer.stem(w) for w in data]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_input=preprocess_reviews(data['corpus'])\n",
    "\n",
    "raw_input\n",
    "\n",
    "my_words=[]\n",
    "for line in raw_input:\n",
    "    line=line.split(' ')\n",
    "    for word in line:\n",
    "        my_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words=[word for word in my_words if len(word)<13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=collections.Counter(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_vocabulary=list(set(filtered_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_updated_vocabulary=[]\n",
    "for i in filtered_words:\n",
    "    if counter.get(i)>1:\n",
    "        new_updated_vocabulary.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65979"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_updated_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter2=collections.Counter(new_updated_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "class TrieNode(object):\n",
    "    \"\"\"\n",
    "    Our trie node implementation. Very basic. but does the job\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, char: str):\n",
    "        self.char = char\n",
    "        self.children = []\n",
    "        # Is it the last character of the word.`\n",
    "        self.word_finished = False\n",
    "        # How many times this character appeared in the addition process\n",
    "        self.counter = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(root, word: str):\n",
    "    \"\"\"\n",
    "    Adding a word in the trie structure\n",
    "    \"\"\"\n",
    "    node = root\n",
    "    for char in word:\n",
    "        found_in_child = False\n",
    "        # Search for the character in the children of the present `node`\n",
    "        for child in node.children:\n",
    "            if child.char == char:\n",
    "                # We found it, increase the counter by 1 to keep track that another\n",
    "                # word has it as well\n",
    "                child.counter += 1\n",
    "                # And point the node to the child that contains this char\n",
    "                node = child\n",
    "                found_in_child = True\n",
    "                break\n",
    "        # We did not find it so add a new chlid\n",
    "        if not found_in_child:\n",
    "            new_node = TrieNode(char)\n",
    "            node.children.append(new_node)\n",
    "            # And then point node to the new child\n",
    "            node = new_node\n",
    "    # Everything finished. Mark it as the end of a word.\n",
    "    node.word_finished = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_count(root, prefix: str):\n",
    "    \"\"\"\n",
    "    Check and return \n",
    "      1. If the prefix exsists in any of the words we added so far\n",
    "      2. If yes then how may words actually have the prefix\n",
    "    \"\"\"\n",
    "    node = root\n",
    "    # If the root node has no children, then return False.\n",
    "    # Because it means we are trying to search in an empty trie\n",
    "    if not root.children:\n",
    "        return False, 0\n",
    "    for char in prefix:\n",
    "        char_not_found = True\n",
    "        # Search through all the children of the present `node`\n",
    "        for child in node.children:\n",
    "            if child.char == char:\n",
    "                # We found the char existing in the child.\n",
    "                char_not_found = False\n",
    "                # Assign node as the child containing the char and break\n",
    "                node = child\n",
    "                break\n",
    "        # Return False anyway when we did not find a char.\n",
    "        if char_not_found:\n",
    "            return 0\n",
    "    # Well, we are here means we have found the prefix. Return true to indicate that\n",
    "    # And also the counter of the last node. This indicates how many words have this\n",
    "    # prefix\n",
    "    return node.counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_checker(root,word:str,desperateness_index=2):\n",
    "    node=root\n",
    "    probable_replacements=[]\n",
    "    found=False\n",
    "    i=0\n",
    "    if isthere(root,word):\n",
    "        return word\n",
    "    if not root.children:\n",
    "        return False\n",
    "    node = root\n",
    "    \n",
    "    for char in word:\n",
    "        if i>3 and len(node.children)==1:\n",
    "            return spell_predictor(root,word[:i])\n",
    "        found_in_child = False\n",
    "        # Search for the character in the children of the present `node`\n",
    "        for child in node.children:\n",
    "            if child.char == char:\n",
    "                node = child\n",
    "                found_in_child = True\n",
    "                break\n",
    "        # We did not find it so add a new chlid\n",
    "        if not found_in_child:\n",
    "            # print('error at '+char)\n",
    "            lister=[]\n",
    "            for a in node.children:\n",
    "                lister.append(a.counter)\n",
    "#             for a in node.children:\n",
    "#                 print(a.char) \n",
    "            if len(lister)>0:\n",
    "                probable_replace=lister.index(max(lister))\n",
    "                new_word_2=word[:i]+node.children[probable_replace].char+word[i+1:]\n",
    "                new_word_1=word[:i]+node.children[probable_replace].char+word[i:]\n",
    "                new_word_3=word[:i]+word[i+1:]\n",
    "                if isthere(root,new_word_1) and not found:\n",
    "                    found=True\n",
    "                    probable_replacements.append(new_word_1)\n",
    "                if isthere(root,new_word_2) and not found:\n",
    "                    found=True\n",
    "                    probable_replacements.append(new_word_2)\n",
    "                if isthere(root,new_word_3)and not found:\n",
    "                    found=True\n",
    "                    probable_replacements.append(new_word_3)\n",
    "                break\n",
    "        i=i+1\n",
    "    if not node.word_finished:\n",
    "        predicted_word=spell_predictor(root,word)\n",
    "        if predicted_word:\n",
    "            probable_replacements.append(predicted_word)\n",
    "            found=True\n",
    "    if not found:\n",
    "        i=0\n",
    "        node = root\n",
    "        for char in word:\n",
    "            for index in range(len(node.children)):\n",
    "                new_word_2=word[:i]+node.children[index].char+word[i+1:]\n",
    "                new_word_1=word[:i]+node.children[index].char+word[i:]\n",
    "                new_word_3=word[:i]+word[i+1:]\n",
    "                if isthere(root,new_word_1) and not found:\n",
    "                    found=True\n",
    "                    probable_replacements.append(new_word_1)\n",
    "                if isthere(root,new_word_2) and not found:\n",
    "                    found=True\n",
    "                    probable_replacements.append(new_word_2)\n",
    "                if isthere(root,new_word_3) and not found:\n",
    "                    found=True\n",
    "                    probable_replacements.append(new_word_3)\n",
    "            for child in node.children:\n",
    "                if child.char == char:\n",
    "                    node = child\n",
    "                    i=i+1\n",
    "                    \n",
    "    if not found and desperateness_index>1:\n",
    "        i=0\n",
    "        node = root\n",
    "        for char in word:\n",
    "            for index in range(len(node.children)):\n",
    "                new_word_1=word[:i]+node.children[index].char+word[i:]\n",
    "                new_word = spell_checker(root,new_word_1,desperateness_index-1)\n",
    "                if new_word:\n",
    "                    return new_word\n",
    "                    found =True\n",
    "            for child in node.children:\n",
    "                if child.char == char:\n",
    "                    node = child\n",
    "                    i=i+1\n",
    "        i=0\n",
    "        node = root\n",
    "        for char in word:\n",
    "            for index in range(len(node.children)):\n",
    "                new_word_2=word[:i]+node.children[index].char+word[i+1:]\n",
    "                new_word = spell_checker(root,new_word_2,desperateness_index-1)\n",
    "                if new_word and not found:\n",
    "                    return new_word\n",
    "                    found =True\n",
    "            for child in node.children:\n",
    "                if child.char == char:\n",
    "                    node = child\n",
    "                    i=i+1\n",
    "                    \n",
    "        i=0\n",
    "        node = root\n",
    "        for char in word:\n",
    "            for index in range(len(node.children)):\n",
    "                new_word_3=word[:i]+word[i+1:]\n",
    "                new_word = spell_checker(root,new_word_3,desperateness_index-1)\n",
    "                if new_word:\n",
    "                    return new_word\n",
    "                    found =True\n",
    "            for child in node.children:\n",
    "                if child.char == char:\n",
    "                    node = child\n",
    "                    i=i+1\n",
    "    if found:\n",
    "        new_word=probable_replacements[0]\n",
    "        return new_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_predictor(root,prefix:str):\n",
    "    node = root\n",
    "    word=prefix\n",
    "    if not root.children:\n",
    "        return False, 0\n",
    "    for char in prefix:\n",
    "        char_not_found = True\n",
    "        # Search through all the children of the present `node`\n",
    "        for child in node.children:\n",
    "            if child.char == char:\n",
    "                # We found the char existing in the child.\n",
    "                char_not_found = False\n",
    "                # Assign node as the child containing the char and break\n",
    "                node = child\n",
    "                break\n",
    "        # Return False anyway when we did not find a char.\n",
    "    \n",
    "    while not node.word_finished:\n",
    "        lister=[]\n",
    "        for child in node.children:\n",
    "            lister.append(child.counter)\n",
    "        next_index=lister.index(max(lister))\n",
    "        word=word+node.children[next_index].char\n",
    "        node=node.children[next_index]\n",
    "        \n",
    "    if(isthere(root,word)):\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isthere(root,word):\n",
    "    node = root\n",
    "    is_there=True\n",
    "    for char in word:\n",
    "        found_in_child = False\n",
    "        for child in node.children:\n",
    "            if child.char == char:\n",
    "                node = child\n",
    "                found_in_child = True\n",
    "                break\n",
    "        if not found_in_child:\n",
    "            is_there=False\n",
    "    if not node.word_finished:\n",
    "        is_there=False\n",
    "    return is_there\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = TrieNode('*')\n",
    "for word in new_updated_vocabulary:\n",
    "    add(root,word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'outlook'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell_checker(root,'otlok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'help'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell_predictor(root,'hel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer = pd.ExcelWriter('new_updated_vocabulary.xlsx')\n",
    "# df=pd.DataFrame(new_updated_vocabulary)\n",
    "# df.to_excel(writer)\n",
    "# writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
